{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAP 4630: The Final Countdown",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RandyT97/CAP4630/blob/master/CAP_4630_The_Final_Countdown.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKQx0Plz0u0K",
        "colab_type": "text"
      },
      "source": [
        "# General Concepts\n",
        "* Deep learning is a subset of ML and ML is a subset of AI\n",
        "\n",
        "## Artificial Intelligence\n",
        "* Field of computer science that attempts to develop a systems that perform tasks that would normally require human intelligence to perform\n",
        "\n",
        "## Machine Learning\n",
        "* \"field of study that gives computers the ability to learn without being explicitly programmed.\" - Arthur Samuel 1959\n",
        "* Dynamic and does not require human intervention to make certain changes\n",
        "\n",
        "*  Supervised ML\n",
        "  * Model is provided with labeled training data\n",
        "  * Example: The Fashion MNNIST data set including the train_labels and test_labels\n",
        "* Unsupervised ML\n",
        "  * Model is not provided with labeled data, it is up to the model to identify patterns\n",
        "* Reinforced Learning\n",
        "  * Model is told to never reach a certain state, then the model trains to avoid that state. No examples with labels are provided.\n",
        "\n",
        "\n",
        "## Deep Learning\n",
        "  * Ths usage brain simulations through neural networks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUXf0RjqTqUQ",
        "colab_type": "text"
      },
      "source": [
        "# Models\n",
        "* Regression Model: Predicts continuous values\n",
        "  * Stock pricing\n",
        "    * You can draw a line through the values and see the relationship between the two features\n",
        "* Classification Model: Predicts discrete values\n",
        "  * Is this image a picture of a bird, plane or Superman?\n",
        "  * See: Fashion MNIST Image Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVh4FdOn8nWm",
        "colab_type": "text"
      },
      "source": [
        "# Building a Model: CNN\n",
        "* A Convolutional Neural Network receives an input feature map: A 3-d matrix consisting of the length and width of the pixels, and the number of channels (3) in a colored image.\n",
        "* Structure of a CNN\n",
        "  * convolution + ReLU + pooling for feature extraction\n",
        "  * A convolution extracts tiles from the feature map and applies filters to them in order to compute enw features\n",
        "  * A ReLU (Rectified Linear Unit) is applied to the convolved feature to introduce nonlinearity to the model where ReLU(x) = max(0,x) that returns x if x>0 and 0 if x<=0\n",
        "    * Pooling: CNN downsamples the feature and reduces the dimensions of the feature map while preserving important information\n",
        "  * Fully connected layer for classification\n",
        "* During training, the CNN extracts meaningful features from the input feature map.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyOWkbLfRRmm",
        "colab_type": "text"
      },
      "source": [
        "# Compiling a model\n",
        "* Optimizers\n",
        "  * Optimizers are optimalization algorithms used to train neural networks to reduce the cost while minimizing loss. It is too inefficient to calculate the loss function of every value over the entire data set in order to find the convergence point\n",
        "    * Gradient Descent:\n",
        "      * Calculates the gradient of the loss curve at the starting point then takes a steep towards the direction of the negative gradient to reduce loss, then adds some magnitude of the gradient to the starting point\n",
        "* Learning rate\n",
        "    * Learning rate is what determines the step size in an optimization algorithm while trying to approach the minimum loss function. \n",
        "    * When defining a learning rate, must balance the rate of convergence and overshooting.\n",
        "      * If convergence is too low, it will take too long to learn\n",
        "      * If it is too fast, will jump over the minima"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83qhGc_DRUM0",
        "colab_type": "text"
      },
      "source": [
        "# Training a Model\n",
        "* A model is trained through learning good values for all the weights and biases from the labeled dataset provided\n",
        "* Loss is the penalty for a bad prediction\n",
        "* Goal is to minimize loss across all examples\n",
        "* Fitting\n",
        " * Fitting a Model requires adjusting the model to best make predictions on new data\n",
        " * There are two issues with the fit of a model that can occur:\n",
        "    * Overfitting\n",
        "      * \"Overfits\" the data its trained on\n",
        "      * Low loss in training but does badly predicting new data\n",
        "      * Caused by making a model more complex than necessary\n",
        "    * Underfitting\n",
        "      * \"Underfits\" the data its trained on\n",
        "      * Incapable of learning from the dataset its trained on\n",
        "* Data Splitting\n",
        "  * Dividing the data set in order to make a training set and a test set for the model\n",
        "    * Sets must be large enough to yield statistically meaningful results and represent the data set as a whole\n",
        "  * Validation Set\n",
        "    * Other than the training and test set, you can reduce the chances of overfitting by using a validation set to evaluate results from the training set, then use the test set to revalidate your results after the model passes the validation set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eXMkWJUd9nW",
        "colab_type": "text"
      },
      "source": [
        "# Finetuning pretrained model\n",
        "* Retrain existing layers to reduce errors\n",
        "* Adjust learning rate based on rate of convergence and loss\n",
        "* Freeze the weight of the first few layers\n",
        "* Train some layers in a pre-trained network"
      ]
    }
  ]
}